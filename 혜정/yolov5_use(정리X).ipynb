{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolov5_use_custom_data1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1dL4ZbE2YRXG"
      ],
      "machine_shape": "hm",
      "mount_file_id": "124Bq39HP-d28Hdyx3QJmIeLIxWEoMskR",
      "authorship_tag": "ABX9TyNhN+ljrE/Ng6F7j4Fj7qa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kikiru328/Bone_Detection/blob/main/%ED%98%9C%EC%A0%95/yolov5_use(%EC%A0%95%EB%A6%ACX).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dL4ZbE2YRXG"
      },
      "source": [
        "## 1. ì‚¬ì „í•™ìŠµëª¨ë¸ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lXuDqEAG-nn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96d0350-ff2f-41a2-97a2-8dab171ca84c"
      },
      "source": [
        "# ì½”ë©ì„ ì´ìš©í•´ì„œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "# ì•„ë˜ì˜ ê³¼ì •ì€ yolov5 íŠœí† ë¦¬ì–¼ê³¼ì •ì¤‘ ì¼ë¶€ì…ë‹ˆë‹¤.\n",
        "# ê¹ƒí—ˆë¸Œ ë§í¬: https://github.com/ultralytics/yolov5 , íŠœí† ë¦¬ì–¼ ë§í¬ : https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\n",
        "\n",
        "# 1) ë¨¼ì €, yolo ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤. ===============================================================\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.9.0+cu111 (Tesla V100-SXM2-16GB)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpkRtWzAHU7l"
      },
      "source": [
        "# train_data.zip íŒŒì¼ì„ ì €ëŠ” '/content'(%pwd) ì— ë„£ì—ˆìŠµë‹ˆë‹¤.\n",
        "# trani_data.zip íŒŒì¼ì˜ êµ¬ì„± : images ì™€ labels í´ë”ë¥¼ ë§Œë“¤ì–´ ë’€ìŠµë‹ˆë‹¤. ê° í´ë” ì•ˆì—ëŠ” train ê³¼ val í´ë”ê°€ ìˆê³ , ì‚¬ì§„ê³¼ ë¼ë²¨ì´ ë“¤ì–´ê°€ìˆìŠµë‹ˆë‹¤.\n",
        "# 2) train_data upzip í•´ì¤ë‹ˆë‹¤===============================================================\n",
        "# !unzip -q ../train_data.zip -d ../"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9JCSZWkIJ9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66d344e-24b1-40f0-c3d8-4eb10baa5ff8"
      },
      "source": [
        "# /contentì˜ yolov5 í´ë”ì•ˆì˜ dataí´ë”ì— custom_data.yaml íŒŒì¼ì„ ë„£ì–´ì¤ë‹ˆë‹¤.\n",
        "# custom_dataì˜ ë‚´ìš©ì„ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
        "# ---------------------------------------------------------------------------------------------------\n",
        "# train: /content/train_data/images/train  # train images (relative to 'path') 50 images\n",
        "# val: /content/train_data/images/val  # val images (relative to 'path') 10 images\n",
        "# test:  # test images (optional)\n",
        "\n",
        "# # Classes\n",
        "# nc: 7  # number of classes\n",
        "# names: ['CARPAL', 'LMCP', 'MMCP', 'TMCP', 'LPIP', 'MPIP', 'IP']  # class names\n",
        "# ----------------------------------------------------------------------------------------------------\n",
        "# 3) *** batch, epochs ì¡°ì ˆí•˜ê³ , custom_data.yaml ìœ¼ë¡œ ìˆ˜ì •í•´ì„œ í´ë”ì— ë„£ì–´ì£¼ê³  ì‹¤í–‰í•©ë‹ˆë‹¤. ==============================================================\n",
        "!python train.py --img 800 --batch 150 --epochs 100 --data custom_data.yaml --weights yolov5s.pt --cache\n",
        "\n",
        "# 3ë²ˆ ê³¼ì •ì˜ ì‹¤í–‰ì´ ì™„ë£Œë˜ë©´ ë§¨ ë§ˆì§€ë§‰ì— Results saved to runs/train/exp ë¼ê³  ì €ì¥ëœ ê²½ë¡œê°€ ëœ¹ë‹ˆë‹¤.\n",
        "# yolov5 í´ë”ì— ê²½ë¡œë¥¼ ë”°ë¼ ë“¤ì–´ê°€ì‹œë©´ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=custom_data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=150, imgsz=800, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ğŸš€ v6.0-39-g5d4258f torch 1.9.0+cu111 CUDA:0 (Tesla V100-SXM2-16GB, 16160.5MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ğŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=7\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     32364  models.yolo.Detect                      [7, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 270 layers, 7038508 parameters, 7038508 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.001171875\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight, 60 weight (no decay), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/team2/preprocessing_com/train_data/labels/train.cache' images and labels... 560 found, 0 missing, 0 empty, 0 corrupted: 100% 560/560 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.8GB ram): 100% 560/560 [00:01<00:00, 493.31it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/drive/MyDrive/team2/preprocessing_com/train_data/labels/val.cache' images and labels... 61 found, 0 missing, 0 empty, 0 corrupted: 100% 61/61 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 61/61 [00:00<00:00, 156.38it/s]\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.89, Best Possible Recall (BPR) = 1.0000\n",
            "Image sizes 800 train, 800 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "  0% 0/4 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 627, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 524, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"train.py\", line 297, in train\n",
            "    imgs = imgs.to(device, non_blocking=True).float() / 255.0  # uint8 to float32, 0-255 to 0.0-1.0\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 1.07 GiB (GPU 0; 15.78 GiB total capacity; 1.13 GiB already allocated; 497.75 MiB free; 1.17 GiB reserved in total by PyTorch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiOjsA1lJaZE"
      },
      "source": [
        "# +) ë°•ìŠ¤ ì˜ˆì¸¡, testí´ë”ë¥¼ ë§Œë“¤ì–´ì„œ ì§€ì •í•´ì£¼ì…”ë„ ë˜ê³ , íŒŒì¼ë§Œ ë„£ì–´ë„ detect ë©ë‹ˆë‹¤. íŠœí† ë¦¬ì–¼ ê³¼ì •ì„ ì°¸ê³ í•˜ì—¬ ì£¼ì„¸ìš”. ì—¬ê¸°ì„œ ì €ëŠ” ì´ê²ƒì„ í™œìš©í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. \n",
        "# !python detect.py --weights runs/train/exp/weights/last.pt --img 320 --conf 0.25 --source ../717.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LFd6QAaYYrS"
      },
      "source": [
        "## 2. ê°ì²´ ì¸ì‹ ë° ì¶”ì¶œí•˜ê¸°."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9t8xsFTJU9r"
      },
      "source": [
        "# 4) ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ ì˜ˆì¸¡(ê°ì²´ì¸ì‹ ë° ì¶”ì¶œ)í•©ë‹ˆë‹¤. ==============================================================\n",
        "\n",
        "#!pip install -qr requirements.txt ì— ëŒ€í•œ ëŸ°íƒ€ì„ ì¬ì‹œì‘ì´ í•„ìš”í•˜ë‹¤ê³  ë– ì„œ ëŸ°íƒ€ì„ì„ ì¬ì‹œì‘í•´ ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
        "# torch.hub.load ëŠ” ê¹ƒí—ˆë¸Œ ë¦¬í¬ì§€í† ë¦¬ ë˜ëŠ” ë¡œì»¬ ë””ë ‰í„°ë¦¬ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. # ìì„¸í•œ ì„¤ëª…ì€ ì„¤ëª… ì‚¬ì´íŠ¸(https://pytorch.org/docs/stable/hub.html)ë¥¼ ì°¸ê³ í•´ ì£¼ì„¸ìš”. # https://runebook.dev/ko/docs/pytorch/hub ì´ ì‚¬ì´íŠ¸ì—ì„œë„ ì„¤ëª…ì´ ì˜ ë˜ì–´ìˆìŠµë‹ˆë‹¤.\n",
        "# ë¦¬í¬ì§€í† ë¦¬ ë˜ëŠ” ë¡œì»¬ ë””ë ‰í„°ë¦¬ ì…ë ¥í›„ custom ì´ ë“¤ì–´ê°„ ìë¦¬ëŠ” ëª¨ë¸ëª…ì…ë‹ˆë‹¤. \n",
        "# model = torch.hub.load('repo_or_dir', 'model')  # yolov5ì—ì„œ ëª¨ë¸ ì¢…ë¥˜ëŠ” yolov5s or yolov5m, yolov5l, yolov5x, custom ì´ë ‡ê²Œ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp/weights/last.pt', force_reload=True) \n",
        "\n",
        "\n",
        "# custom ëª¨ë¸ì€ pathì— íŒŒì¼(ê°€ì¤‘ì¹˜íŒŒì¼) ê²½ë¡œë¥¼ ì ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤. \n",
        "# ìœ„(ë¡œì»¬)ì—ì„œ train ê³¼ val ë°ì´í„°ë¡œ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸(ì¦‰, ëª¨ë¸ ì •ì˜ ë° ì‚¬ì „ í›ˆë ¨ ëœ ê°€ì¤‘ì¹˜)ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
        "\n",
        "# ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë„£ì–´ë³´ê³  ì˜ˆì¸¡ê°’ì„ ë°›ì•„ì˜µë‹ˆë‹¤.\n",
        "img = '/content/sample.jpg'  # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì§€ì •í•´ì¤ë‹ˆë‹¤.\n",
        "results = model(img)  \n",
        "# crops = results.crop(save=True)  - render() ì „ì— crop ì‚¬ìš©í•˜ë©´ ë°•ìŠ¤ ì³ì§€ê¸° ì „ì— ì˜ë¼ì„œ ì €ì¥ë¨!!!  < ì €í¬ê°€ ëª¨ì„ íŒŒì¼ì…ë‹ˆë‹¤ã…\n",
        "\n",
        "# results.print() ëª¨ë¸ì— ì ìš©ëœ ê²°ê³¼ê°’ì´ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
        "# image 1/1: 800x600 1 CARPAL, 1 LMCP, 1 MMCP, 1 TMCP, 1 LPIP, 1 MPIP, 1 IP\n",
        "# ì´ë¯¸ì§€ í•˜ë‚˜ë¥¼ ì ìš©í–ˆê³ , í¬ê¸°ëŠ” 800*600 ì´ë©° ì¸ì‹ëœ ê°ì²´ì˜ ë¼ë²¨ê³¼ ê°œìˆ˜ì…ë‹ˆë‹¤.\n",
        "# Speed: 12.7ms pre-process, 12.9ms inference, 1.4ms NMS per image at shape (1, 3, 640, 480) # ê·¸ ë°–ì˜ ê²°ê³¼ì…ë‹ˆë‹¤."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA1DxOLMRN1Q"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "\n",
        "# results.imgs # array of original images (as np array) passed to model for inference\n",
        "# results.render()  # updates results.imgs with boxes and labels\n",
        "# render()ì„ ì´ìš©í•˜ì—¬ ë¼ë²¨ì´ ë¶™ì€ ì´ë¯¸ì§€ê²°ê³¼íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ np.squeezeë¡œ ê¸¸ì´ê°€ 1ì¸ ì¶•ì„ ì œê±°í•©ë‹ˆë‹¤. - resultsì˜ image shapeê°€ (1, 3, 640, 480) ì¸ê²ƒì„ ìœ„(results.print())ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "plt.imshow(np.squeeze(results.render()))\n",
        "crops = results.crop(save=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRbGB2KSVivT"
      },
      "source": [
        "# ë°•ìŠ¤ì³ì§„ë¶€ë¶„ ì˜ë ¤ì„œ ì €ì¥ë¨. ê²½ë¡œì„¤ì • ê°€ëŠ¥. \n",
        "# render()í›„ë¼ì„œ ë°•ìŠ¤ì™€ ê°™ì´ ì €ì¥ë¨.\n",
        "crops = results.crop(save=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L27n902-XmuD"
      },
      "source": [
        "# ë°•ìŠ¤ì³ì§„ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "save_img = np.squeeze(results.render())\n",
        "import cv2\n",
        "cv2.imwrite('/content/sample.jpg', save_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTJyr8YzX8LP"
      },
      "source": [
        "# ê²°ê³¼ë¥¼ pandasë¡œ ë°›ì•„ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "print(results.pandas().xyxy[0])\n",
        "#          xmin        ymin       xmax      ymax  confidence  class    name\n",
        "# 0  171.875000  450.312500  390.00000  630.9375    0.937988      0  CARPAL\n",
        "# 1  230.625000  274.218750  287.50000  350.0000    0.911621      2    MMCP\n",
        "# 2  421.250000  377.187500  481.25000  429.6875    0.902832      3    TMCP\n",
        "# 3  220.468750  144.140625  269.53125  182.8125    0.895020      5    MPIP\n",
        "# 4   67.500000  253.125000  108.43750  291.5625    0.890137      4    LPIP\n",
        "# 5  124.765625  327.187500  185.62500  382.8125    0.873047      1    LMCP\n",
        "# 6  487.187500  309.843750  532.81250  352.8125    0.850586      6      IP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHK_irUy_B75"
      },
      "source": [
        "## ìƒ˜í”Œ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZhSixfO-_Li"
      },
      "source": [
        "!pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHbvjBR7_KDT",
        "outputId": "95f5a1bb-f589-461c-a0dd-f84bf3815d8f"
      },
      "source": [
        "import torch\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/team2/last.pt', force_reload=True) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ğŸš€ 2021-11-1 torch 1.9.0+cu111 CUDA:0 (Tesla V100-SXM2-16GB, 16160.5MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7029004 parameters, 0 gradients, 15.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1RwaV4fC02q",
        "outputId": "3ae206ad-1a94-4a00-b447-bd338459490e"
      },
      "source": [
        "# model1 = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/best_0.pt', force_reload=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 ğŸš€ 2021-10-31 torch 1.9.0+cu111 CUDA:0 (Tesla V100-SXM2-16GB, 16160.5MB)\n",
            "\n",
            "Fusing layers... \n",
            "Model Summary: 213 layers, 7029004 parameters, 0 gradients, 15.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLO2PubD_KJd",
        "outputId": "8d337dc2-3d1a-406d-f5ff-9f329d2c6553"
      },
      "source": [
        "# Images # 572ë²ˆê¹Œì§€, 230ì œì™¸\n",
        "imgs = []\n",
        "for i in range(1,230):\n",
        "  try :\n",
        "    img = f'/content/drive/MyDrive/team2/preprocessing_com/female/{i}_F.jpg'\n",
        "    imgs.append(img)\n",
        "  except:\n",
        "    print(i)\n",
        "    continue\n",
        "\n",
        "print(len(imgs))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBtnNOSHENlz",
        "outputId": "e517f47a-4edc-4e16-a40c-beedaeb15fec"
      },
      "source": [
        "for i in range(231,573):\n",
        "  try :\n",
        "    img = f'/content/drive/MyDrive/team2/preprocessing_com/female/{i}_F.jpg'\n",
        "    imgs.append(img)\n",
        "  except:\n",
        "    print(i)\n",
        "    continue\n",
        "\n",
        "print(len(imgs))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sCRKDcJ7pZX",
        "outputId": "60c28615-0e79-4bf7-fd98-4e11cfbdf840"
      },
      "source": [
        "results1 = model(imgs)\n",
        "results1.render()\n",
        "crops1 = results1.crop(save=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saved 571 images to \u001b[1mruns/detect/exp2\u001b[0m\n",
            "Saved results to runs/detect/exp2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W31-Uljb9njg"
      },
      "source": [
        "import cv2\n",
        "save_path = '/content/drive/MyDrive/team2/ppt/female/render/'\n",
        "for i in range(0,572):\n",
        "  plt_img = np.squeeze(results1.render())[i]\n",
        "  cv2.imwrite(save_path+f'{i+1}_F.jpg', plt_img)\n",
        "  # plt.imshow(plt_img)\n",
        "  # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uWToFr8HbBs"
      },
      "source": [
        "imgs = []\n",
        "for i in range(1,666):\n",
        "  try :\n",
        "    img = f'/content/drive/MyDrive/team2/preprocessing_com/male/{i}_M.jpg'\n",
        "    imgs.append(img)\n",
        "  except:\n",
        "    print(i)\n",
        "    continue\n",
        "\n",
        "print(len(imgs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P44AU2qjHdgD"
      },
      "source": [
        "results2 = model(imgs)\n",
        "crops3 = results2.crop(save=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk_kgfSIHh-a"
      },
      "source": [
        "import cv2\n",
        "save_path = '/content/drive/MyDrive/team2/ppt/male/render/'\n",
        "for i in range(0,665):\n",
        "  plt_img = np.squeeze(results2.render())[i]\n",
        "  cv2.imwrite(save_path+f'{i+1}_M.jpg', plt_img)\n",
        "  # plt.imshow(plt_img)\n",
        "  # plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr3bSFthH2MD"
      },
      "source": [
        "def save_img(name,mm):\n",
        "  for i in range(1,573):\n",
        "    try : \n",
        "      if i != 230 :\n",
        "        img = f'/content/runs/detect/exp2/crops/{name}/{i}_F.jpg'\n",
        "        img = cv2.imread(img)\n",
        "        save_img = f'/content/drive/MyDrive/team2/ppt/{name}/{i}_F_{mm}.jpg'\n",
        "        cv2.imwrite(save_img, img)\n",
        "      except:\n",
        "        print(name, i)\n",
        "        continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7BVRDfiIPuC"
      },
      "source": [
        "save_img('CARPAL','cp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehMiMvJsIRy6"
      },
      "source": [
        "save_img('IP','ip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xwfcjYTIR3z"
      },
      "source": [
        "save_img('LMCP','lm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNvICV_XIR8K"
      },
      "source": [
        "save_img('LPIP','lp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4LRYIAYISAx"
      },
      "source": [
        "save_img('MMCP','mm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igw4EuEBISEp"
      },
      "source": [
        "save_img('MPIP','mp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nIMh6LZISJL"
      },
      "source": [
        "save_img('TMCP','tm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAFg0RSxIqwL"
      },
      "source": [
        "# import cv2\n",
        "def save_img_male(name,mm):\n",
        "  for i in range(1,666):\n",
        "    try : \n",
        "      img = f'/content/runs/detect/exp3/crops/{name}/{i}_M.jpg'\n",
        "      img = cv2.imread(img)\n",
        "      save_img = f'/content/drive/MyDrive/team2/ppt/{name}/{i}_M_{mm}.jpg'\n",
        "      cv2.imwrite(save_img, img)\n",
        "    except:\n",
        "      print(name, i)\n",
        "      continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsohg3_6JWpy"
      },
      "source": [
        "save_img_male('CARPAL','cp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCIcQEcpJWp3"
      },
      "source": [
        "save_img_male('IP','ip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gMcIem7JWp3"
      },
      "source": [
        "save_img_male('LMCP','lm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD_Nb6KbJWp3"
      },
      "source": [
        "save_img_male('LPIP','lp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x_uO14oJWp3"
      },
      "source": [
        "save_img_male('MMCP','mm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbLN45mPJWp4"
      },
      "source": [
        "save_img_male('MPIP','mp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbC01FwWJWp4"
      },
      "source": [
        "save_img_male('TMCP','tm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFdPj5xgIq0p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zkPM-00Iq26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFkYmCCpH2Pb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuVu4Q-jH2Ry"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSwaMKScH2Ty"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "EX2_KSu67t1H",
        "outputId": "3f003002-787b-46c0-e3f7-dfd53eb5095f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.imshow(np.squeeze(results2.render()))\n",
        "crops = results2.crop(save=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-743366acee6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# crops1 = results1.crop(save=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (571, 800, 600, 3) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAMbElEQVR4nO3bcYikd33H8ffHXFNpGrWYFeTuNJFeGq+2kHRJU4SaYlouKdz9YZE7CG1KyKE1UlAKKZZU4l9WakG41l6pRAWNp3+UBU8CtZGAeDEbEmPuQmQ9bXNRmjOm/iMaQ7/9YybtZL+7mSd3szO39f2ChXme+e3Md4fhfc8881yqCkma9IpFDyDpwmMYJDWGQVJjGCQ1hkFSYxgkNVPDkOQTSZ5O8tgm9yfJx5KsJXk0yTWzH1PSPA05Yrgb2PcS998I7Bn/HAb+4fzHkrRIU8NQVfcDP3yJJQeAT9XICeA1SV4/qwElzd+OGTzGTuDJie0z433fX78wyWFGRxVccsklv3XVVVfN4Oklbeahhx76QVUtvdzfm0UYBquqo8BRgOXl5VpdXZ3n00s/d5L8+7n83iy+lXgK2D2xvWu8T9I2NYswrAB/PP524jrgR1XVPkZI2j6mfpRI8lngeuCyJGeAvwZ+AaCqPg4cB24C1oAfA3+6VcNKmo+pYaiqQ1PuL+A9M5tI0sJ55aOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6RmUBiS7EvyRJK1JHdscP8bktyX5OEkjya5afajSpqXqWFIchFwBLgR2AscSrJ33bK/Ao5V1dXAQeDvZz2opPkZcsRwLbBWVaer6jngHuDAujUFvGp8+9XA92Y3oqR5GxKGncCTE9tnxvsmfRC4OckZ4Djw3o0eKMnhJKtJVs+ePXsO40qah1mdfDwE3F1Vu4CbgE8naY9dVUerarmqlpeWlmb01JJmbUgYngJ2T2zvGu+bdCtwDKCqvga8ErhsFgNKmr8hYXgQ2JPkiiQXMzq5uLJuzX8AbwdI8mZGYfCzgrRNTQ1DVT0P3A7cCzzO6NuHk0nuSrJ/vOz9wG1JvgF8Frilqmqrhpa0tXYMWVRVxxmdVJzcd+fE7VPAW2c7mqRF8cpHSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUGAZJjWGQ1BgGSY1hkNQYBkmNYZDUDApDkn1JnkiyluSOTda8M8mpJCeTfGa2Y0qapx3TFiS5CDgC/D5wBngwyUpVnZpYswf4S+CtVfVsktdt1cCStt6QI4ZrgbWqOl1VzwH3AAfWrbkNOFJVzwJU1dOzHVPSPA0Jw07gyYntM+N9k64Erkzy1SQnkuzb6IGSHE6ymmT17Nmz5zaxpC03q5OPO4A9wPXAIeCfkrxm/aKqOlpVy1W1vLS0NKOnljRrQ8LwFLB7YnvXeN+kM8BKVf2sqr4DfItRKCRtQ0PC8CCwJ8kVSS4GDgIr69b8C6OjBZJcxuijxekZzilpjqaGoaqeB24H7gUeB45V1ckkdyXZP152L/BMklPAfcBfVNUzWzW0pK2VqlrIEy8vL9fq6upCnlv6eZHkoapafrm/55WPkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLIvyRNJ1pLc8RLr3pGkkizPbkRJ8zY1DEkuAo4ANwJ7gUNJ9m6w7lLgz4EHZj2kpPkacsRwLbBWVaer6jngHuDABus+BHwY+MkM55O0AEPCsBN4cmL7zHjf/0pyDbC7qr74Ug+U5HCS1SSrZ8+efdnDSpqP8z75mOQVwEeB909bW1VHq2q5qpaXlpbO96klbZEhYXgK2D2xvWu87wWXAm8BvpLku8B1wIonIKXta0gYHgT2JLkiycXAQWDlhTur6kdVdVlVXV5VlwMngP1VtbolE0vaclPDUFXPA7cD9wKPA8eq6mSSu5Ls3+oBJc3fjiGLquo4cHzdvjs3WXv9+Y8laZG88lFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWDwpBkX5InkqwluWOD+9+X5FSSR5N8OckbZz+qpHmZGoYkFwFHgBuBvcChJHvXLXsYWK6q3wS+APzNrAeVND9DjhiuBdaq6nRVPQfcAxyYXFBV91XVj8ebJ4Bdsx1T0jwNCcNO4MmJ7TPjfZu5FfjSRnckOZxkNcnq2bNnh08paa5mevIxyc3AMvCRje6vqqNVtVxVy0tLS7N8akkztGPAmqeA3RPbu8b7XiTJDcAHgLdV1U9nM56kRRhyxPAgsCfJFUkuBg4CK5MLklwN/COwv6qenv2YkuZpahiq6nngduBe4HHgWFWdTHJXkv3jZR8Bfhn4fJJHkqxs8nCStoEhHyWoquPA8XX77py4fcOM55K0QF75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqRkUhiT7kjyRZC3JHRvc/4tJPje+/4Ekl896UEnzMzUMSS4CjgA3AnuBQ0n2rlt2K/BsVf0q8HfAh2c9qKT5GXLEcC2wVlWnq+o54B7gwLo1B4BPjm9/AXh7ksxuTEnztGPAmp3AkxPbZ4Df3mxNVT2f5EfAa4EfTC5Kchg4PN78aZLHzmXoBbmMdX/PBWw7zQrba97tNCvAr53LLw0Jw8xU1VHgKECS1apanufzn4/tNO92mhW217zbaVYYzXsuvzfko8RTwO6J7V3jfRuuSbIDeDXwzLkMJGnxhoThQWBPkiuSXAwcBFbWrVkB/mR8+4+Af6uqmt2YkuZp6keJ8TmD24F7gYuAT1TVySR3AatVtQL8M/DpJGvADxnFY5qj5zH3ImynebfTrLC95t1Os8I5zhv/YZe0nlc+SmoMg6Rmy8OwnS6nHjDr+5KcSvJoki8neeMi5pyY5yXnnVj3jiSVZGFfsw2ZNck7x6/vySSfmfeM62aZ9l54Q5L7kjw8fj/ctIg5x7N8IsnTm10XlJGPjf+WR5NcM/VBq2rLfhidrPw28CbgYuAbwN51a/4M+Pj49kHgc1s503nO+nvAL41vv3tRsw6dd7zuUuB+4ASwfKHOCuwBHgZ+Zbz9ugv5tWV0Uu/d49t7ge8ucN7fBa4BHtvk/puALwEBrgMemPaYW33EsJ0up546a1XdV1U/Hm+eYHRNx6IMeW0BPsTo/678ZJ7DrTNk1tuAI1X1LEBVPT3nGScNmbeAV41vvxr43hzne/EgVfcz+jZwMweAT9XICeA1SV7/Uo+51WHY6HLqnZutqarngRcup563IbNOupVRhRdl6rzjQ8bdVfXFeQ62gSGv7ZXAlUm+muREkn1zm64bMu8HgZuTnAGOA++dz2jn5OW+t+d7SfT/F0luBpaBty16ls0keQXwUeCWBY8y1A5GHyeuZ3Qkdn+S36iq/1roVJs7BNxdVX+b5HcYXcfzlqr670UPNgtbfcSwnS6nHjIrSW4APgDsr6qfzmm2jUyb91LgLcBXknyX0WfLlQWdgBzy2p4BVqrqZ1X1HeBbjEKxCEPmvRU4BlBVXwNeyeg/WF2IBr23X2SLT4rsAE4DV/B/J3F+fd2a9/Dik4/HFnQCZ8isVzM6KbVnETO+3HnXrf8Kizv5OOS13Qd8cnz7MkaHvq+9gOf9EnDL+PabGZ1jyALfD5ez+cnHP+TFJx+/PvXx5jDwTYzq/23gA+N9dzH6FxdGpf08sAZ8HXjTAl/cabP+K/CfwCPjn5VFzTpk3nVrFxaGga9tGH30OQV8Ezh4Ib+2jL6J+Oo4Go8Af7DAWT8LfB/4GaMjr1uBdwHvmnhtj4z/lm8OeR94SbSkxisfJTWGQVJjGCQ1hkFSYxgkNYZBUmMYJDX/AwqkUdV2nfELAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dF25w3kvMUAH",
        "outputId": "74dbb378-7b91-4e08-a381-7276aa79bdbc"
      },
      "source": [
        "imgs = []\n",
        "for i in range(1,666):\n",
        "  try :\n",
        "    img = f'/content/drive/MyDrive/team2/preprocessing_com/male/{i}_M.jpg'\n",
        "    imgs.append(img)\n",
        "  except:\n",
        "    print(i)\n",
        "    continue\n",
        "\n",
        "print(len(imgs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roCF5xQt_KL8"
      },
      "source": [
        "# results1 = model(imgs)\n",
        "results2 = model1(imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMkOIZkyBjl5",
        "outputId": "c6bfa95a-5adf-45a4-eb3e-b208409d06ed"
      },
      "source": [
        "crops2 = results2.crop(save=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saved 665 images to \u001b[1mruns/detect/exp4\u001b[0m\n",
            "Saved results to runs/detect/exp4\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYSEwOjN71LX"
      },
      "source": [
        "plt.imshow(np.squeeze(results2.render()[0]))\n",
        "crops = results2.crop(save=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wnZ-bK8Fypg"
      },
      "source": [
        "import cv2\n",
        "for i in range(1,573):\n",
        "  if i != 230 :\n",
        "    img = f'/content/runs/detect/exp3/crops/CARPAL/{i}_F.jpg'\n",
        "    img = cv2.imread(img)\n",
        "    save_img = f'/content/drive/MyDrive/team2/ppt/CARPAL/{i}_F.jpg'\n",
        "    cv2.imwrite(save_img, img)\n",
        "  else : continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U00BNAcPIO_B"
      },
      "source": [
        "# import cv2\n",
        "def save_img(name,mm):\n",
        "  for i in range(1,573):\n",
        "    if i != 230 :\n",
        "      img = f'/content/runs/detect/exp3/crops/{name}/{i}_F.jpg'\n",
        "      img = cv2.imread(img)\n",
        "      save_img = f'/content/drive/MyDrive/team2/ppt/{name}/{i}_F_{mm}.jpg'\n",
        "      cv2.imwrite(save_img, img)\n",
        "    else : continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGJzgfKZI6s5"
      },
      "source": [
        "save_img('CARPAL','cp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCU8Bnw6beaZ"
      },
      "source": [
        "save_img('IP','ip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pjHvHOlbgFw"
      },
      "source": [
        "save_img('LMCP','lm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkaM-SaHbg8f"
      },
      "source": [
        "save_img('LPIP','lp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-8u2mukbh1p"
      },
      "source": [
        "save_img('MMCP','mm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF9aS0b5biTq"
      },
      "source": [
        "save_img('MPIP','mp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUkRtlEbjEp"
      },
      "source": [
        "save_img('TMCP','tm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTC6G8avLEqH",
        "outputId": "1128b7d2-affb-4e73-a87b-f480f1f62c78"
      },
      "source": [
        "imgs = []\n",
        "for i in range(1,667):\n",
        "  try :\n",
        "    img = f'/content/drive/MyDrive/team2/preprocessing_com/male/{i}_M.jpg'\n",
        "    imgs.append(img)\n",
        "  except:\n",
        "    print(i)\n",
        "    continue\n",
        "\n",
        "print(len(imgs))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSpIEtPUK5QU"
      },
      "source": [
        "# import cv2\n",
        "def save_img_male(name,mm):\n",
        "  for i in range(1,666):\n",
        "    try : \n",
        "      img = f'/content/runs/detect/exp4/crops/{name}/{i}_M.jpg'\n",
        "      img = cv2.imread(img)\n",
        "      save_img = f'/content/drive/MyDrive/team2/crop_img/male/{name}/{i}_M_{mm}.jpg'\n",
        "      cv2.imwrite(save_img, img)\n",
        "    except:\n",
        "      print(name, i)\n",
        "      continue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGlQTP5PMDfr"
      },
      "source": [
        "save_img_male('CARPAL','cp')\n",
        "save_img_male('IP','ip')\n",
        "save_img_male('LMCP','lm')\n",
        "save_img_male('LPIP','lp') #537, 647  < last.ptë¡œëŠ” í•´ê²°ë¨. \n",
        "save_img_male('MMCP','mm')\n",
        "save_img_male('MPIP','mp')\n",
        "save_img_male('TMCP','tm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBZJoECFPu18",
        "outputId": "5a1af1bb-095a-43c5-84f0-2ad5a28bff9f"
      },
      "source": [
        "again_img = '/content/drive/MyDrive/team2/preprocessing_com/male/537_M.jpg'\n",
        "results2 = model1(again_img)\n",
        "crops2 = results2.crop(save=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saved 1 image to \u001b[1mruns/detect/exp5\u001b[0m\n",
            "Saved results to runs/detect/exp5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnslhRpdQJvp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.imshow(np.squeeze(results2.render()))\n",
        "crops = results2.crop(save=False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzBDsvzWQ-hl",
        "outputId": "d253dd43-db4c-4821-9aa6-e1f5506dd14e"
      },
      "source": [
        "again_img = '/content/drive/MyDrive/team2/preprocessing_com/male/537_M.jpg'\n",
        "results1 = model(again_img)\n",
        "crops1 = results1.crop(save=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saved 1 image to \u001b[1mruns/detect/exp6\u001b[0m\n",
            "Saved results to runs/detect/exp6\n",
            "\n"
          ]
        }
      ]
    }
  ]
}